Scheduler
    maximizing resources
        - utilization

    challenges
        - how to differentiate between IO vs CPU bound processes
        - limited information

    simflication assumptions
        - every job runs for the same amount of time
        - all jobs "arrive" at the same time
        - once scheduled, jobs run to completion
        - all jobs are CPU bound
        - runtimes for each job is known

    terms
        job = process
        workload = collection of running jobs
        non-preemptive = process isnt interrupted
        preemptive = process can be interrupted

    metrics of success
        - cpu utilization (idle time)
        - turnaround time (time between job arrival and job completion)
        - wait time (time spent ready but not running)
        - response time (time it takes for job to recieve user input/user interaction)
            - not always a clear computation
        - throughput (# jobs by time)

    users really only care about the appearance of performance though
        programs open quickly
        programs respond quickly

    Qualities of a process
        burst time          
        I/O requirements
        priority                - Kind of knows
        age                     - Knows
        other dependencies
        run time

    Scheduling Algorithms
        Batch scheduling
            first come first serve (FIFO queue)
                fair
                simple
                can be predictable
                convoy effect (1 super long job before 1000 short jobs; reduces throughput)
            shortest job first
                optimal for maximizing throughput
                non-preemptive
            shortest job next
                AKA shortest remaining job first
                AKA shortest remaining job next
                preemptive
                burst times compared at job arrival
                P1 @ 0 = 5, P2 @ 1 = 3, P3 @ 3 = 4
                ** make gantt chart and calculate wait time, turnaround time
            priority based scheduling
                taking age or some other metric into account when scheduling
            round robin scheduling
                everyone gets some amount of time on the cpu
                fcfs w/preemption based on quantum
                highly predictable
                low variance, potentially higher wait times
            multi-level feedback queueing
                create queues w/ different priorities
                1. if the priority(A) > priority(B), then A runs
                2. if priority(A) == priority(B), then A + B run using round robin
                3. when job arrives, placed in highest priority queue
                4a. if a job uses entire quantum, its priority is reduced
                4b. if job gives up the CPU before quantum is up (if job gets blocked)
                    it stays in current queue
                5. after some time S (age), move job to top-most queue

                    S is usually annecdotally derived; no way to figure it out perfectly

                stack:
                    
                    &A      <- points to previous base pointer (A)
                    &main
                    a
                    local
                    local
                    .
                    .
                    .
                    A

        Problems!:
            synchronization
                processes can be interrupted at any time
                threads can be interrupted at any time
                critical sections
                hogging critical sections due to happenstance

                any solution to the critical selection problem must have:
                    1) mutual exclusion (correctness)
                        only let one thread into critical section at a time
                        accomplished through lock
                    2) progress (fairness)
                        every thread will eventually enter critical section if it wants
                        cant let one thread continuously lock the critical section
                    3) bounded wait (performance)
                        limit the amount of time someone will wait for a lock to become available
                    cant rely on knowing the number of CPU's or speed of CPU's

        Solution 1: Peterson's solution
            software only solution
            for two threads (i, j) only

            // shared variables
            int turn
            bool flay[2]

            // thread i
            do{
                flag[i] = True
                turn = j
                while(flag[j] && turn == j); //wait
                
                // critical section
                
                flag[i] = false;
            } while(True)

        Hardware Solutions
            1) disable interrupts
                not very practical
                what if multiple CPU's?
            2) atomic instructions (does these things in 1 instruction)
                accomplishes by locking memory

                TestSetLock (lock)
                    bool TestAndSet(bool *lock){
                        bool ret = *lock;
                        *lock = TRUE;
                        return ret;
                    }

                    lock = FALSE;
                    do{
                        while(TestAndSet(&lock));   // this is called a spin lock
                        // CRITICAL SECTION
                        lock = FALSE;
                    } while(true)

                    does not solve 100%, only solves mutual exclusion; no progress/bounded wait

                    when to use spin lock? when critical section is small enough such that spin lock wait is
                    less expensive than context switching

                Swap
    
    Semaphores
        integer variable used for synchronization
            accessed through two atomic operations:

            wait(S){
                < insert lock here to achieve mutual exclusion? >
                S--;
                while(S < 0);
            }

            signal(S){
                S++;
            }

        Binary Semaphore = when S set to 1
            mutex lock
            do{
                wait(mutex);

                // critical section

                signal(mutex);
            } while (TRUE);

        can do synchronization
        can act as a barrier (limit number of threads allowed at a time)
            maximize core usage


        blocking semaphore
            semaphore S

            wait(S){
                S -> value--
                while(S->value < 0){
                    add_thread(S->queue)
                    sleep() <- magical thread sleep function
                }
            }

            signal(S){
                S->value++
                if (s->value <=0 ){
                    += get_thread(S->queue)
                    wakeup #
                }
            }

            // when thread waits, it gets added to a queue

            typedef struct_zem_t{
                int value
                pthread_cond_t cond
                pthread_mutex_t lock    

            }

            void zem-wait(zem_t *z){
                mutex_lock(&z->lock)    <- all of these functions are in the pthread library
                while(z->value <= 0)
                    cond_wait(&z->cond, &z->lock)   <- lock must reacquired before returning
                z->value --
                mutex_unlock(&z->lock)
            }

            void zen-post(zem_t *z){
                mutex_lock(&z->lock)
                z->value++
                cond_signal(&z->cond)
                mutex_unlock(&z->lock)
            }

        problems with locks/semaphores:
            T1:
                lock(S) 1
                lock(T) 3

            T2:
                lock(T) 2
                lock(S) 4

            T1, T2 need the variable locked by the opposite thread
            enter deadlock

        classic synchronization problems
            consumer/producer
            bounded buffer
            atomicity violations
                how threads access variables

                T1
                if (thd -> proc_info){
                    fputs(thd->proc_info...)
                    ...
                }

                T2
                if thd->proc_info = NULL

            ordering
                T1: (parent)
                    mThread = PIR_CreateThread(mMain, ...)
                
                T2:
                    void mMain(...){
                        // if this runs before assignment of mThread in T1, can cause issues
                        m State = mThread -> State
                    }

            dining philosopher's problem
                to eat, need 2 chopsticks
                to think, need 0 chopsticks
                if 5 philosophers and 5 chopsticks
                    how to maximize throughput

                
                void P(int i){
                    while(1){
                        think()

                        ** one solution = acquire two chopsticks at same time?
                            still have issue with release(), that also needs to be atomic
                            but if we make that atomic, then only 1 person can eat at a time
                            very subtle problems

                        wait(mutex)

                        acquire(chopstick[i])       // can get deadlock if all get preempted after this instructions
                        acquire(chopstick[i+1%N])

                        signal(mutex)
                        eat()

                        **
                        release(chopstick[i])
                        release(chopstick[i+i%N])
                    }
                }



                N = 5
                left (i+n-1) %n
                left (i+1) %n
                thinking 0
                hungry 1
                eating 2
                state[n]
                semaphore mutex = 1
                semaphore S[n]

                void p(int i){
                    while(1){
                        think()
                        take_chopsticks(i)
                        eat()
                        put_chopsticks(i)
                    }
                }

                take_chopsticks(int i){
                    wait(&mutex)
                    state[i] = hungry
                    test(i)
                    signal(&mutex)
                    wait(&s[i])
                }

                put_chopsticks(int i){
                    wait (&mutex)
                    state[i] = thinking
                    test(left)
                    test(right)
                    signal(mutex)
                }

                test(int i){
                    if(state[i] == hungry && 
                        state[left] != eating && 
                        state[right] != eating){
                            state[i] = eating
                            signal(&s[i])
                    }
                }

        deadlock
            a set of processes/threads are waiting for an event that only another process/thread in that set can cause

            resource deadlock
            communication deadlock
                A sends a message then wait()
                B sends something back then wait()
                works until a message gets blocked in transit
            necessary conditions for deadlock
                mutual exclusion
                    one resource held by one process at a time
                hold & wait
                    holding one resource and waiting for another
                no resource preemption
                    resource can only be released voluntarily
                circular wait
                    a set of processes/threads {p0, p1, ... pn} such that Pi is waiting on resources used by P(i+1) % n